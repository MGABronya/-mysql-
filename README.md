#  MGAronya的mysql开发手册（学习笔记）

[TOC]



## 关于引擎

### 引擎的划分

#### InnoDB

适用于处理大量的短期事务，拥有良好的性能和自动崩溃恢复特性

#### MyIsam

拥有全文索引、压缩、空间函数等特性，但是在高并发下容易出现性能问题，且崩溃后无法安全恢复，必须使用备份恢复。

#### Archive

只支持insert和select操作，支持索引，是一个针对高速插入和压缩做了优化的简单引擎

#### Blackhole

没有存储机制，会丢弃所有插入的数据，但是日志会正常记录，可以用于分发备库

#### CSV

可以将CSV文件作为mysql的表来处理

#### Federated

访问其它mysql服务器的代理，其会创建一个道远程mysql服务器的客户端连接，并将查询传输到远程服务器执行，然后提取需要的数据。该引擎可能会带来一些问题，如有需要可以了解其的改进版本FederatedX

#### Memory

在内存中的表，对于查找操作非常快，写入性能低，重启后表数据就会丢失。（mysql内部的临时表所用的引擎即为Memory，在数据量超过限制，则会变为MyIsam）

#### NDB集群

用于mysql集群，当考虑集群时可能会使用到该引擎

#### 第三方引擎

正对某些特定项目，可以在第三方中找到开源的适配引擎。

### 引擎的选择建议

在没有特殊要求时尽量选用Innodb引擎。

### 切换引擎的工具

Percona Toolkit工具箱的pt-online-schema-change

## 基准测试

### 基准测试目标

- 验证某些假设
- 测试运行情况
- 模拟、规划业务增长
- 测试不同硬件、软件、操作系统配置

实际上我们只能做大概的测试，来确定系统的余量有多少。

### 基准测试的策略

1.集成式测试：针对整个系统的整体测试

2.单组件测试：单独测试mysql

### 基准测试的指标

- 吞吐量：单位时间内事务的处理数
- 响应时间或者延迟：测试任务所需的整体时间
- 并发性：正在工作的并发操作或同时工作中的线程数或者连接数
- 可扩展性：增加数倍的工作量

测试对于用户而言最重要的指标（即收集需求）

### 基准测试的方法

- 选用真实数据的全集
- 使用正确的数据发布
- 模拟多用户场景，尽可能匹配用户的真实行为
- 测试时间足够长
- 注意系统的预热时间

### 基准测试工具

1.集成测试工具：http_load(对web服务器进行测试)

2.单组件测试工具：sysbench(多线程系统压测工具)

## 服务器性能剖析

### 所谓性能剖析

在不同的需求下性能的含义也有所不同，这里将性能定义为响应时间（包括执行等待时间和执行时间）

性能剖析的步骤：

1.测量任务所花费的时间

2.对结果进行统计和排序，将重要的任务排到前面

### 对应用程序的性能剖析

使用工具New Relic

### 剖析Mysql查询

1.使用慢查询日志（其包含了show profile 和 show status的所有输出）

2.使用pt-query-digest工具分析日志，定位需要优化的单条查询

3.在慢查询中获得关于这些查询的足够有用的信息

### 诊断间歇性问题

使用诊断触发器

- 从show status 或者 show processlist 中的某些状态作为监控指标（每隔一秒获取一次等等）
- 避免误报和漏检（阈值设置，只有在进入了阈值才触发）

使用pt-stalk监控数据，pt-collect进行数据的收集（由pt-stalk调用），pt-sift可以用于快速检测收集到的样本数据

使用pt-summary和pt-mysql-summary可以获得服务器的状态信息、参数配置信息以及软硬件环境信息。

### 导致资源性能低下的原因

- 资源被过度使用，余量无法支持正常工作
- 资源没有被正确配置
- 资源损坏或失灵

大多数时候需要深入问题并考虑各种可能，而不只是优化慢查询

## Schema与数据类型优化

### 选择优化的数据类型

- 尽量选择可以正确存储数据的最小数据类型
- 尽量选择简单的数据类型，它们通常使用更少的CPU周期（有时可以用int类型代替其它数据）
- 尽量避免NULL
- 尽量避免BLOB和TEXT类型，把这些大数据存入文件而表中只记录文件的位置。在所有使用到BLOB或者TEXT的地方使用substring(column, length)
- 使用枚举(ENUM)代替常用的字符串
- 除了需要特殊行为，尽量用timestamp而不是datetime，因为它占用的空间更少。
- 当需要保存很多true/false值，考虑set类型
- 标识符尽量选择整形类型（因为它们快且小）

### schema设计时应当避免的陷阱

- 太多的列
- 太多的关联
- 枚举过大的数据集
- 对极小的数据集不使用枚举
- 自己发明NULL（用某些常数代替NULL，这会使代码逻辑复杂，很多时候不如直接使用NULL）

### 范式与反范式

范式化：每个事实数据会出现且只出现一次

反范式化：冗余的信息

- 范式化的更新操作通常比反范式化快，因为它很少或者没有重复数据
- 范式化的表通常更小，可以很好的放在内存里，执行操作会更快
- 范式化的表更少需要distinct和group by语句
- 反范式化的表往往可以针对某类查询拥有更高的查询效率，且能减少关联操作

可以混用范式和反范式，在反范式的设计中利用触发器做重复数据的更新

### 缓存表和汇总表

缓存表：存储从其他表中获取的数据的表，可以加快特定的查询速度

汇总表：使用group by语句聚合数据的表，用于记录一些数据用于特定查询

必须决定缓存表和汇总表时实时维护数据还是定期重建

影子表：在重建表时，建立一个new表，并把旧表命名为old，再将new表重命名为目标表，这样做可以快速回滚

物化视图：使用工具Flexviews可以实现物化视图，即正在存在于磁盘中的视图，并用各种策略刷新，可以用于实现缓存表和汇总表。

计数器表：对于任何想更新计数器的事务而言都会在这里排队执行，所以需要使用多行的计数器并最后计算计数器们的加和。

### 加快alter table的速度

方案一：现在不提供服务的机器上执行alter table的操作，然后和提供服务的主库进行切换

方案二：使用影子拷贝，创建一个新表，并通过重命名和删表操作交换两张表。可以用于影子拷贝的工具：online schema change, openark toolkit, Percona Toolkit

方案三：修改表的.frm文件

在载入数据时，禁用索引，载入数据，然后重新启用索引。Percona Server可以自动完成这些步骤

1.用需要的表结构创建一张表，但是不包括索引

2.载入数据到表中以构建.MYD文件

3.按照需要的结构创建另外一张空表，这次要包含索引。这会创建需要的.frm和.MYI文件

4.获取读锁并刷新表

5.重命名第二张表的.frm和.MYI文件，让Mysql认为这是第一张表的文件

6.释放读锁

7.使用repair table来重建表的索引。该操作会通过排序来构建所有索引。

## 创建高性能的索引

### 索引类型

#### B-Tree索引

- 全值匹配
- 匹配最左前缀
- 匹配列前缀（后序列无法继续使用索引）
- 匹配范围值（后序列无法继续使用索引）
- 精准匹配某一列并范围匹配另一列
- 只访问索引的查询（覆盖索引）

#### 哈希索引

- 哈希索引只包含哈希值和行指针，而不存储字段值。
- 哈希索引不是按照索引值顺序排序的
- 哈希索引不支持部分索引列匹配查找
- 哈希索引只支持等职比较查询
- 访问哈希索引的数据非常快，除非有很多哈希冲突

只有Memory引擎显示支持哈希索引，NDB集群引擎也支持哈希索引。Innodb引擎有一个功能叫做“自适应哈希索引”，当某些索引值使用频繁时，它会在内存中基于B-Tree索引之上再建立一个哈希索引，此行为对用户透明。

创建自定义哈希索引：将某一列的索引删去，增加一列原列哈希值的索引，可用触发器维护

### 高性能的索引策略

- 简化where，始终将索引列单独放在比较符号的一侧
- 确保索引选择性足够高（过滤掉更多的行）
- 对blob，text，很长的varchar类型使用前缀索引
- 优化索引列的顺序（选择性高的列在前）
- 创建覆盖索引
- 注意innodb的聚集索引（主键，在没有主键时选择唯一非空列，没有这样的列则会默认自建），这使在Innodb中按主键顺序插入行的效果更好，同时这会让innodb的二级索引的叶子节点保存的为主键的值
- 可以在where语句中用in () 语法将范围查询改为多个等值查询，从而充分利用多列索引，同时可以避免多个范围查询
- mysql中unique()唯一限制和primary key主键限制都是通过索引实现的，避免对已经拥有限制的列再做唯一索引，否则会产生冗余索引
- 使用pt-index-usage找出未使用或者使用极少的索引

### 维护索引和表

可以尝试运行check table来检查是否发生了表损坏

可以通过设置innodb_force_recovery参数进入innodb的强制恢复模式

可以运行analyze table重新生成表的统计信息以引导优化器规划正确的执行计划

可以关闭innodb_stats_on_metadata参数避免某些表的索引统计信息每次查询都自动更新

可以通过optimize table或者导出后顺序导入的方式整理数据，以消除碎片（行碎片，行间碎片，剩余空间碎片），也可以在线删除索引后重新添加

## 查询性能优化

### 优化数据访问

#### 是否向数据库请求了不需要的数据

关于行：可以使用limit限制返回的行数

关于列：只返回真正需要用到的列

#### mysql是否在扫描额外的数据

查看一次查询扫描的行数和返回的行数，如果扫描大量的数据但只返回少数的行

- 使用索引覆盖扫描
- 改变库结构（如使用汇总表）
- 重写查询

### 重构查询的方法

当一个大查询（复杂查询）无法胜任时，查看是否可以将一个大查询（复杂的查询）分解为多个小查询（简单的查询）：

- 切分查询，每个查询功能一样，但只完成一小部分
- 分解关联查询（在应用层完成关联）

### 查看查询状态

使用show full processlist命令

### 查询优化器

语法解析器和预处理对sql语句进行解析，并生成一棵对应的解析树，预处理器将进一步检查解析树是否合法。接下来就会由优化器将解析树转化为执行计划。

mysql使用基于成本的优化器，优化器将通过存储引擎提供的统计信息选择生成哪一种执行计划。

以下是优化器能够处理的优化类型：

- 重新定义关联的表的顺序
- 将外连接转化为内连接
- 使用等价变化原则
- 优化count()、min()、max()
- 预估并转化为常数表达式
- 覆盖索引扫描
- 子查询优化
- 提前终止查询
- 等值传播
- 列表IN()的比较

可以使用straight_join关键字指定关联顺序

### 优化器的局限性

#### 关联子查询

在in()中的子查询，mysql会将相关的外层表压倒子查询中。这种情况并不一定会产生性能差距，但是最好还是写成inner join或者exists

#### union的限制

如果合并后只取出20条记录，应当在合并前让每个表就只取出20条记录，优化器并不会做这一步

#### 最大值和最小值优化

即使有索引，mysql仍然会做全表扫描。这时可以用use index(primary) ... limit 1来去出最小或者最大的数据

#### 在同一张表上查询并同时更新

如果mysql不允许对同一张表同时进行查询和更新，可以通过使用生成表的形式绕过这条限制

### 优化器提示

- high_priority、low_priority: 定义语句的优先级
- delayed：对insert和replace有效，该做法会将插入到行数据放入缓冲区，在表空闲时批量写入。
- straight_join: 指定关联顺序，当关联表很多时手动指定可以减少优化器的工作
- sql_small_result、sql_big_result: 只对select有效，告诉优化器结果集很小或很大。
- sql_buffer_result: 将查询结果放到临时表中，尽可能快的释放表锁，这会让服务器端使用更多的内存
- sql_cache、sql_no_cache: 结果集是否应该存放在查询缓存中
- use index、ignore index、 force index: 使用或不适用哪些索引
- optimizer_search_depth: 控制穷举执行计划时的限度，当查询长时间在'Statistics'状态时降低此参数 

在mysql升级后，使用pt-upgrade工具，检查sql是否于老版本一样，返回相同的结果

### 优化特定类型的查询

#### 优化count查询

使用近似值、索引覆盖扫描、增加汇总表等

#### 优化关联查询

- 确保on或者using的列上有索引
- 确保group by和order by的列只涉及一个表且列上有索引

#### 优化子查询

写成inner join或者exists，大多数情况还是需要查看实际运行的效果

#### 优化group by和distinct

使用提示sql_big_result和sql_small_result，在关联表中使用group by时，标识列往往是最佳选择。

group by会自动按照分组的字段进行排序，可以使用order by null让mysql不对其进行文件排序，也可以在group by语句中添加desc或者asc指定排序序列

#### 优化group by with rollup

尽量将rollup功能移动到应用程序中处理

#### 优化limit分页

- 尽量使用索引覆盖扫描
- 可以对返回的数据进行延迟关联，即先在limit限制下利用索引覆盖查询到所有主键，再用这些主键查询其它所需要的列
- 记录上一次limit后主键的结果值为书签，在接下来翻页时从书签处开始
- 使用汇总表或冗余表

#### 优化union查询

手工将where、limit、order by等子句下推到union的各个子查询中

如果不需要消除重复的行，一定要使用union all，否则整个临时表都需要做唯一性检查

### 静态查询分析

pt-query-advisor可以用于解析查询日志、分析查询模式，给出可能存在潜在问题的查询。

### 使用用户自定义变量

- 使用自定义变量的查询，无法使用查询缓存
- 不能在使用常量或者标识符的地方使用自定义变量
- 不能显示的声明自定义变量的类型
- 未定义的变量不会引起报错

1.优化排名语句：

因为语句在每行的执行顺序并不一定如你所愿，所以可以考虑先将行排列好生成临时表，然后再对每行做排名

2.避免重复查询刚刚更新的数据：

可以在更新语句中安排自定义变量记录更新的数据

3.统计更新和插入的数量：

在语句中增加变量自增的部分

4.确定取值的顺序：

让变量的赋值和取值发生在查询的同一阶段

5.编写偷懒的union：

如果在一个表中找到了需要的数据，在union的其它表中可能就不需要再执行查询，此时可以利用自定义变量记录是否找到需要的数据。

### 查询基础原则

- 尽量少做事，可以的话就不要做任何事情。除非迫不得已，否则不要使用轮询。
- 尽可能块地完成需要做的事情 。尽量用update代替先select for update再update的写法
- 将一些不适合mysql完成的事情转移到应用层面上（如一些复杂的计算）

## mysql高级特性

### 分区表

对底层表的封装，每个底层表内有自己的索引，但是没有全局索引。主要目的是将数据按照一个较粗的力度分在不同的表里。

在创建表时使用partition by子句定义每个分区存放的数据。

使用场景：

- 表非常大以至于无法全部都放在内存中，或者只在表的最后有热点数据，其它都是历史数据
- 分区表的数据更容易维护（可以直接清空整个分区，或对一个独立分区进行优化、检查、恢复等）
- 分区表的数据可以分布在不同的物理设备上，从而高效的利用多个硬件设备
- 分区表可以避免某些特殊的瓶颈，如innodb的单个索引的互斥访问，锁竞争等

分区表的使用限制：

- 一个表最多只能有1024个分区
- 如果分区字段中有主键或者唯一的列，那么所有主键列和唯一索引列都必须包含进来
- 分区表中无法使用外键约束

如何使用分区表：

- 全量扫描数据，不要任何索引。使用where子句的条件将需要的数据限制在少数分区中
- 索引数据并分离热点。如果数据有明显的热点，则将热点数据放入独立分区并使用索引。
- 使用分区函数的列本身做比较，否则mysql无法过滤分区

分区表的一些问题：

- 如果定义的索引列和分区列不匹配，会导致查询无法进行分区过滤。因为索引是在在表中单独建立的，如果where使用该索引，可能导致mysql扫描每一个分区内对应的索引。
- 对于范围分区而言，选择分区的成本可能很高。每一次写入一行数据都可能要完整扫描一次分区定义列表，建议限制范围分区数量（少于100）。对于键分区和哈希分区则没有这样的问题。
- 在过滤完成前分区表会锁住所有的底层表，这项操作的成本可能很高，所以可以用批量操作的方式降低单个操作的此类开销。
- 重组分区或者类似alter操作的成本可能会很高。

### 视图

由select语句建立，对视图的操作服务器会使用两种算法

合并算法：服务器将视图sql和查询sql进行合并后运行

临时表算法：服务器先运行视图sql生成临时表，然后运行查询sql

可以用 explain语句查看视图的select_type得知算法类型

如果视图中包含了group by、distinct、聚合函数、union、子查询等无法在原表记录和视图记录中建立一一映射关系时，mysql会使用临时表算法生成视图。

不能对视图创建触发器，不能使用drop table命令删除视图。

临时表算法生成的视图无法更新。

视图可以用于某次连接生成伪临时表，也可用于在重构schema时修改视图的底层结构而不影响代码运行。

### 外键约束

外键通常需要每次在修改数据时都要在另外一张表中执行一次查找操作。

如果外键约束成为性能瓶颈，考虑使用触发器代替外键，或者使用enum类型，或者将约束转移至应用层

### 在MySQL中存储代码

- 在服务器内部运行，离数据最近
- 是一种代码重用，可以统一业务规则
- 简化代码的维护和版本更新
- 帮助提升安全
- 服务器端可以缓存存储过程的执行计划，如果反复调用，可以降低小号
- mysql没有提供好用的开发工具
- 存储代码效率比应用层稍差些
- 存储过程会给服务器带来额外的压力
- mysql无法控制存储程序的资源消耗
- 与复制配合的不好

#### 存储过程和函数

- 优化器无法使用关键字deterministic来优化单个查询中多次调用存储函数的情况
- 优化器无法评估存储函数的执行成本
- 每个连接都有独立的存储过程的执行计划缓存
- 存储程序与复制配合的很差

存储程序越小、越简单越好，将更复杂的逻辑较给应用层

#### 触发器

- 对每个表的每一个事件，最多只能定义一个触发器
- mysql只支持基于行的触发
- 触发器可以掩盖服务器背后的工作
- 触发器的问题很难排查
- 触发器可能导致死锁和等待
- 触发器检查innodb数据的一致性时需要小心mvcc，在检查一致性时使用select for update等

#### 事件

定时任务，事件在一个独立事件调度线程中被初始化，可以通过日志查看每个事件的执行，或者通过表information_schema.events查看每个事件的状态。

### 游标

mysql在服务器端提供只读的、单向的游标。当打开游标时需要完成整个查询，并将查询结果放入临时表，此时可以推动游标取出每一行的数据。如果只需要结果中的一部分，使用limit限制结果集的行数。

### 绑定变量

客户端向服务器发送一个sql语句的原型，如insert into tbl(col1, col2, col3) value(?, ?, ?);

- 在服务器端只需要解析一次sql语句
- 在服务器端某些优化器的工作只需要执行一次，因为它会缓存一部分的执行计划 
- 以二进制的方式只发送参数和句柄，比每次都发送ascⅡ的效率更高
- 仅仅是参数，而不是整个查询语句需要发送到服务器端，网络开销会更少
- mysql在存储参数时，直接将其存放在缓存中，不再需要在内存中多次复制

- 绑定变量是会话级别的，连接之间不能共用绑定变量句柄
- 如果只执行一次sql，绑定变量反而会有额外的开销
- 不能在存储函数中使用绑定变量

### 插件

- 存储过程插件：procedure analyse
- 后台插件：Handler-Socket
- information_schema插件
- 全文解析插件
- 审计插件
- 认证插件

### 字符集和校对

1.创建对象时的默认设置：

- 创建数据库的时候，将会根据服务器上的character_set_server设置来设定该数据库的默认字符集
- 创建表的时候，将根据数据库的字符集设置看指定这个表的字符集设置
- 创建列的时候，将根据表的设置指定列的字符集设置

2.服务器和客户端通信时的设置：

- 服务器端总是假设客户端是按照character_set_client设置的字符来传输数据和sql语句的
- 当服务器收到客户端的sql语句时，它先将其转换成字符集character_set_connection。它还使用这个设置来决定如何将数据转换为字符串
- 当服务器端返回数据或者错误信息给客户端时，它会将其转换为character_set_result

可以使用charset()、collation()、coercibility()定位各种字符集相关的错误

可以使用前缀和collate子句指定字符串的字符集或者校对字符集

建议：使用完全统一的字符集

### 全文索引

对数据表的某一条记录，mysql会将需要的索引的列全部拼接成一个字符串，然后进行索引

myIsam的全文索引是一类特殊的B-Tree索引，共有两层。第一次是所有关键字，然后对于每一个关键字的第二层，包含的是一组相关的文档指针。

- 停用词列表的词都不会被索引。默认的停用词根据通用英语的使用来设置，可以使用参数ft_stopword_file指定一组外部外键来使用自定义的停用词。
- 对于长度大于ft_min_word_len的词语和长度小于ft_max_word_len的词语，都不会被索引

#### 自然语言的全文索引

在整个索引中出现次数越少的词语，匹配时的相关度就越高。相反，非常常见的单词将不会搜索。

使用where子句中的match against来使用全文索引，match()中指定的列必须和全文索引中指定的列完全相同，否则无法使用全文索引。

这类查询自动按照相似度进行排序。可以使用order by match against子句调整各个列相似度的权重，前提是某个单独计算权重的列拥有全文索引。这样做需要文件排序，并不高效。

#### 布尔全文索引

在against中添加 in boolean mode关键字，这会对against中的字符串做额外的解析：

dinosaur 包含“dinosaur”的行rank更高

~dinosaur 不包含“dinosaur”的行rank更高

+dinosaur 必须包含“dinosaur”

-dinosaur 必须不包含“dinosaur”

dino* 包含以“dino”开头的单词的行rank更高

#### 全文索引的限制

- 如果内存无法装下全部索引，那么搜索速度可能非常慢
- 修改一段文本的100个单词，需要100次索引操作
- 全文索引会有更多的碎片，需要频繁的使用optimize table操作
- 当出现match against语句，mysql一定会使用全文索引
- 全文索引不存储索引列的实际值，不可能用作索引覆盖扫描
- 除了相关性排序，全文索引不能用作其它的排序。其它排序只能使用文件排序。

### 分布式（XA）事务

分布式事务可以然那个存储引擎级别的ACID扩展到数据库层面，甚至可以扩展到多个数据库之间，这需要通过两阶段提交实现。

内部XA事务：即使一个存储引擎参与的事务仍然需要XA事务，因为需要记录二进制日志。这会破坏Mysql内部的批量提交，使得多次额外的fsync()调用（强制事务提交到磁盘），可以设置关闭二进制日志，并将innodb_support_xa设置为0。这样做会降低安全性，建议使用带电池保护的RAID卡写缓存。

外部XA事务：XA事务是一种在多个服务器之间同步数据的方法。如果由于某些原因不能使用mysql自身的复制，或者性能并不是瓶颈的时候，可以尝试使用。

### 查询缓存

用于缓存先前查询的结果，并在之后重复查询时快速返回。大多数需要默认关闭查询缓存，除非查询缓存真的很有用。可以先分配几十兆的空间观察查询缓存的运行情况。

当Qcache_hits / Qcache_insert 大于 3 : 1时，查询缓存是有效的，但最好能达到10 : 1

- query_cache_type:是否打开查询缓存
- query_cache_size:查询缓存使用的总内存空间，单位是字节，必须是1024的整数倍
- query_cache_min_res:在查询缓存中分配内存块时的最小单位。这个值太小，则浪费的空间更小，但是会导致更频繁的内存申请操作。这个值太大，碎片会很多。建议取值(query_cache_size - Qcache_free_memory)/Qcache_queries_in_cache,也可以使用flush query cache完成碎片整理，或者用rest query cache情况查询缓存
- query_cache_limit:mysql能够缓存的最大查询结果

 优化方法：

- 用多个小表代替一个大表对查询缓存有好处。这个设计将会使得失效策略能够在一个更合适的粒度上进行
- 批量写入时只需要一次缓存失效，所以相比单条写入效率更好。
- 因为缓存空间太大，在过期操作的时候可能会导致服务器僵死。
- 对于写密集的应用，最好禁用查询缓存
- 因为对互斥信号量的竞争，有时直接关闭查询缓存对读密集的应用也会有好处。

## 优化服务器设置

任何打算长期使用的设置都应该写到全局配置文件

如果动态的设置这些变量，要注意mysql关闭时可能丢失这些配置。每次更改后，应该检查show global variables的输出，确认语句按照期望改变了。

使用show global status查看工作负载，最好为高峰和非高峰的时间的值做几个快照。也可以使用工具pt-mext。

innotop也可以监控服务器的负载。

### 内存的配置

1.确定可以使用内存的上限。+

2.确定每个连接mysql需要使用多少内存，例如排列缓冲和临时表。（mysql使用的内存一般在2GB以下）

3.确定操作系统需要多少内存。(如果没有发生虚拟内存交换，则内存足够，一般为1-2GB或者总内存*0.05)

4.把剩下的内存全部给mysql的缓存。

### MyIsam的配置

- key_buffer_size:

  这个变量可以一次性为键缓冲区分配所有指定的空间，并刷新键缓存。mysql允许创建多个键缓存。设置为0时，mysql会丢弃缓存在该缓存中的索引，为一个不存在的键缓存设置，会创建新的键缓存。

  建议配置不要超过myisam索引的总大小（查询information_schema表的index_length字段，把它们的值相加），或者不超过操作系统缓存保留总内存的25%，两者取更小值。

  通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads /key_read_requests应该尽可能的低，至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE ‘key_read%'获得)。
  即使没有myisam表，依然需要将key_buffer_size设置为较小值（8-64M），因为有时系统会创建myisam临时表。

- delay_key_write:

  键缓冲延迟，可以设置为off，on，all，开启后键缓冲更新时将不会第一时间写回磁盘，而是在表关闭后写回。这样做会带来安全问题，断电时会失去更新的索引导致表损坏，但是也会带来一些性能提升,建议只在存在更新事务繁多的myisam表时开启选项。

- myisam_recover:

  该选项控制myisam如何恢复受损表。当安全性要求较高时，建议打开为backup,force强制恢复并且创建备份，特别是服务器中只有一些小的myisam表的时候。这样做会使性能受损，但是可以避免数据损坏。

- concurrent_insert:

  可以配置myisam打开并发插入（在读时插入）。0：不允许并发插入。1：表中没有空洞时允许并发插入。2.强制并发插入到末尾，如果没有线程在读，则插入到空洞中，这样做会使表有更多碎片。配合delay_key_write效果更佳。

- low_priority_update:

  使insert、replace、delete、update语句的优先级比select低，这个选项可以让myisam的select拥有很好的并发度。

- read_buffer_size:

  为需要全表扫描的myisam数据表线程指定缓存大小，是针对每个connection的，每次查询时才会一次性分配指定的大小。

  如果对myisam表的顺序扫描请求非常频繁，频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能。

- myisam_block_size:

  该值表示mysql键缓存块大小，调整为操作系统的页大小即可。 

### Innodb的配置

- innodb_buffer_pool_size:

  innodb缓冲池，将（内存上限-连接使用的内存-操作系统使用的内存）/1.05的值分配给该值即可。

- innodb_stats_on_persistent:

  innodb数据字典在每次重启后会重新统计信息，这需要大量的时间。打开此选项将会把数据字典持久化至磁盘。

- innodb_stats_on_metadata:

  关闭该选项可以避免表统计信息（数据字典）频繁刷新。

- innodb_open_file:

  表示innodb打开的.ibd文件数量限制，建议设置的足够大使服务器能够同时打开所有的.ibd文件

- innodb_log_file_size:

  该参数指定了重做日志的大小，建议配置的足够大（1G）

- innodb_log_files_in_group:

  重做日志的镜像总数，建议设置为3

- innodb_log_buffer_size:

  重做日志缓存池的大小，通常8MB（默认值）已经足够了，当内存足够大，可以分配32-128MB

- innodb_flush_log_at_trx_commit:

  该变量决定了日志缓冲的刷新策略。

  0：把日志缓冲写道日志文件，每秒刷新一次。

  1：将日志缓冲到日志文件，并且每次事务提交都刷新到持久化存储，则是默认设置。

  2：每次提交时把日志缓冲写道日志文件，但不刷新。每秒刷新一次。

  2一般是更合适的，但是至多在断电时会丢失1秒的事务。如有需要可以选择1并将日志文件放到带电池保护的raid卷中。

- innodb_flush_method:

  可以配置innodb如何跟文件系统相互作用。

  fdatasync：用fsync()刷新数据和日志文件，默认值。

  0_direct: 用fsync()刷新文件到磁盘，但是会通知操作系统不要缓存数据，也不要预读，可以避免双重缓存。建议搭配带有写缓存的raid卡。

- innodb_data_home_dir:

  指定表空间的目录。

- innodb_data_file_path:

  定制表空间文件。可以定制多个表空间文件还有它们的大小。一定要给每个文件规定一个空间上限，当不够用时可以增加一个表空间文件提供更多的空间（比起直接改空间上限，增加一个表空间文件的操作更简单）

- innodb_file_per_table:

  每一个表都将会生成以独立的文件方式来进行存储，每一个表都有一个.frm表描述文件，还有一个.ibd文件。 其中这个文件包括了单独一个表的数据内容以及索引内容，默认情况下它的存储位置也是在表的位置之中。建议开启，这会使每个表处理起来更方便。

- innodb_doublewrite:

  控制innodb是否使用双写缓冲。

- sync_binlog:

  控制mysql怎么刷新二进制日志到磁盘。为0时由操作系统决定什么时候后刷新缓存。为非0值时表示两次刷新到磁盘的动作之间间隔了多少次写二进制日志写操作。设为1可以获得安全保证，同时也会损失性能，建议与带电池保护写缓存的raid控制器搭配使用。

- innodb_thread_concurrency:

  限制一次性可以由多少线程进入内核，建议设定为$CPU数量*磁盘数量*2$

- innodb_thread_sleep_delay:

  并发的两段策略时线程第一次休眠的时间（微秒），在有大量小查询的情况下调小该值。

- innodb_concurrency_tickets:

  线程的票据数量，当有很多运行时间极长的查询，调大该值。

- innodb_thread_concurrency:

  控制多少个线程可以在同一时间提交。当并发线程较多时可以提高该值。

### 基本配置

- tmp_table_size、max_heap_table_size:

  这两个设置控制使用Memory引擎的内存临时表能够使用多打的内存，超过这个值的临时表会被转化为磁盘myisam表。

  建议将这两个变量简单的设置为相同的值即可，例如32M。

- max_connections:

  服务器最多接受的连接数量，超过后客户端会被拒绝服务。

  建议设置的足够大（100-500），可以观察Max_used_connection查看服务器连接的尖峰以此来调节此值。

- table_cache_size:

  表高速缓存的大小(对innodb的重要性很小)。每当MySQL访问一个表时，如果在表缓冲区中还有空间，该表就被打开并放入其中，这样可以更快地访问表内容。

  建议观察默认值的性能在考虑是否作调整，其不应该大于10000。

  通过检查峰值时间的状态值Open_tables和Opened_tables，可以决定是否需要增加table_cache的值。如果发现open_tables等于table_cache，并且opened_tables在不断增长，那么就需要增加table_cache的值（上述状态值可以使用SHOW STATUS LIKE ‘Open%tables’获得）。

- open_files_limit:

  进程能使用的最大文件描述(FD)符数量 ，通常 open_files_limit至少要增大到4096，如果没有什么特殊情况，则设置成8192。 

- thread_cache_size:

  该变量指定了mysql可以保存在缓存中的线程数。

  可以查看Threads_created，如果每秒创建的线程大于10个，则考虑调高此值。

  更好的观察方法是观察Threads_connected通常保持在的范围，如果范围在[a,b]，则取b-a的值便足够了。

- query_cache_type:

  是否打开查询缓存。

- query_cache_size:

  查询缓存使用的总内存空间，单位是字节，必须是1024的整数倍。修改此值时mysql会清空查询缓存，这需要一些时间。当Qcache_hits / Qcache_insert 大于 3 : 1时，查询缓存是有效的，但最好能达到10 : 1。

- query_cache_min_res:

  在查询缓存中分配内存块时的最小单位。这个值太小，则浪费的空间更小，但是会导致更频繁的内存申请操作。这个值太大，碎片会很多。建议取值(query_cache_size - Qcache_free_memory)/Qcache_queries_in_cache,也可以使用flush query cache完成碎片整理，或者用rest query cache情况查询缓存。

- query_cache_limit:

  mysql能够缓存的最大查询结果。

- read_rnd_buffer_size:

  用在sort查询之后 ，以保证获取以顺序的方式获取到查询的数据。mysql只会在有查询需要使用才会为该缓存分配内存，并且只会分配该参数指定大小的所有内存。

  如果有很多order by 查询语句，增长此值能够提升性能。 

- sort_buffer_size:

  在排序时立刻分配该参数指定大小的所有内存。

  应该把此参数设置的小一些，在某些查询需要排序时，再在连接中把它调大，执行完成后恢复为default。

### 安全和稳定的配置

- expire_logs_days:

  让服务器在指定的天数之后清理旧的二进制日志。如果启用了二进制日志，则应该打开该选项。建议留下7-14天的二进制日志。

- max_allowed_packet:

  防止服务器发送太大的包，或者控制多大的包可以被接受，如果需要复制服务器，可能需要调到16MB或者更大。

- max_connect_errors:

  可以将客户端连接拉黑的最大数量。如果服务器可以重复抵御蛮力攻击，可以把这个值设置的很大，以有效地禁用主机黑名单。

- skip_name_resolve:

  在验证时关闭DNS查找。建议打开这个选项，然而这么做需要把基于主机名的授权改为IP地址、通配符，或者特定主机名“localhost”，因为基于主机名的账号会被禁用。

- read_only:

  这个选项禁止没有特权的用户在备库做变更，只接受从主库传输过来的变更，不接受从应用来的变更。强烈建议把备库设置为只读模式。

- skip_slave_start:

  这个选项可以阻止备库自动启动复制。在崩溃后自动启动复制是不安全的，所以需要禁止自动启动。

- slave_net_timeout:

  这个选项控制被备库发现跟主库的连接已经失败并且需要重连之前等待的时间。默认值是一个小时，建议设置为一分钟或者更短。

- sync_master_info、sync_relay_log、sync_relay_log_info:

  这些选项可以在复制中将备库的状态文件同步到磁盘。当有很好的硬件，打开这些选项。如果复制中出现了fsync()出现的延时问题，则关闭它们。

### 高级innodb设置

- innodb:

  在默认引擎为innodb时，把这个值设置为force，表示只有在innodb可以启动时，服务器才会启动。

- innodb_autoinc_lock_mode:

  该选项控制innodb如何生成自增主键值。高并发插入时，自增主键可能时一个瓶颈。可以配置该参数为0、1（默认值）、2，数字越大并发性越好，但2会让单次查询返回的自增值不连续。

- innodb_buffer_pool_instances:

  可以将缓冲池分成多端，可以提升高负载多核集器的可扩展性。可以将此值设置为cpu的核心数后再做调整。

- innodb_io_capacity:

  这个值告诉innodb服务器有多大的io能力，大概参考值为：单盘SAS/SATA 200， SAS*12 RAID10  2000， SSD 5000， FUSION-IO 50000

- innodb_read_io_threads和innodb_write_io_threads:

  这些选项控制有多少后台线程可以被I/O操作使用。可以简单的把这个选项的值设置为可以提供I/O能力的磁盘数量。

- innodb_strict_mode:

  这个选项会让mysql在某些条件下把警告改成抛错。这会使一些有隐患的表无法创建。在恢复备份时可能就不希望打开这个选项了。

- innodb_old_blocks_time:

  这个变量指定一个页面从LRU链表的年轻部分转移到老年部分必须经过的毫秒数，建议设置为1000毫秒。

利用基准测试迭代优化这些参数。在剖析服务器性能时也能展现出哪些配置有问题。

## 复制

### 复制解决的问题

- 数据分布
- 负载均衡
- 备份
- 高可用性和故障切换
- mysql 升级测试

### 配置复制

#### 主库和备库均是刚安装好且为默认的数据

1.在每台服务器上创建复制账号

在主库创建一个用户，并赋予replication slave（或者replication client）权限，备库io线程以该用户名连接到主库并读取其而二进制日志。

````mysql
grant repliction slave, replication client on *.* to repl@'192.168.0.%' identified by 'password';
````

在备库和主库上都创建该账号。

2.配置主库和备库

假设主服务器server1，需要打开二进制日志指定一个独一无二的服务器id，在主库的my.cnf文件中增加或修改如下内容

````
log_bin = mysql-bin
server_id = 10
````

一种通用的方法是使用服务器ip地址的末8位作为服务器id，但是要保证它们是不变且唯一的。

备库上也需要在my.cnf中添加类似的配置，并且同样需要重启服务器

````
log_bin = mysql-bin
server_id = 2
relay_log = /var/lib/mysql/mysql-relay-bin
log_slave_updates = 1
read_only = 1
````

relay_log: 指定中继日志的位置和命名

log_slave_updates: 允许备库将其重放的事件也记录到自身的二进制文件中

3.通知备库连接到主库并从主库复制数据

在备库上使用change master to告诉备库连接到主库并重放其二进制日志

````mysql
change master to master_host = 'server1',
master_user = 'repl',
master_password = 'password',
master_log_file = 'mysql-bin.000001',
master_log_pos = 0;
````

master_log_pos参数设置为0表示日志从头开始读起。可以通过show slave status语句来检查复制是否正确执行。

允许下面的命令开始复制

````mysql
start slave;
````

可以在主库和备库上查看show processlist查看线程状态。

#### 从另一个服务器开始复制

需要三个条件让主库和备库保持同步

- 在某个时间点的主库的数据快照
- 主库当前的二进制日志文件，和获得数据快照时在该二进制日志文件中的偏移量。通过show master status查找这些值
- 从快照时间到现在的二进制日志

下面是一些从别的服务器克隆备库的方法：

- 使用冷备份

  关闭主库，把数据复制到备库。重启主库后，使用新的二进制文件，然后再备库通过执行change master to执行这个文件的起始处。

- 使用热备份

  如果仅使用了myisam表，可以在主库运行时使用mysqlhotcopy或rsync来复制数据

- 使用mysqldump

  这是一种逻辑备份。如果只包含innodb表，那么可以用以下命令来转储主库数据并将其加载到备库，然后设置相应的二进制日志坐标。

  ````
  mysqldump --single-transaction --all-databases --master-data=1--host=server1 \ |mysql --host=server2
  ````

- 使用快照或备份

  只要直到对应的二进制日志坐标，就可以使用主库的快照或者备份来初始化备库。

- 使用Percona Xrabackup

  这是个基于快照的备份，热备份，还原过程快且可靠。

- 使用另外的备库

  可以使用任何一种提及的克隆或者拷贝技术来从任意一台备库上将数据克隆到另外一台服务器。注意，不能使用show master status来获得主库的二进制日志坐标，而是在获取快照时使用show slave status来获取备库在主库上的执行位置。


#### 推荐的复制配置

- sync_binlog=1

  主库上最重要的选项，使mysql每次在提交事务前会将二进制日志同步到磁盘上，保证在服务器崩溃时不会丢失事件。只适用于二进制日志，不适用于中继日志。

- innodb_flush_logs_at_trx_commit、innodb_support_xa=1、innodb_safe_binlog

  应用于innodb上的配置

- log_bin=/var/lib/mysql/mysql-bin

  指明二进制日志的名字，以保证二进制日志名在所有服务器上都是一致的

- relay_log=/path/to/logs/relay-bin

  设置relay_log可以避免中继日志文件基于机器名来命名

- skip_slave_start

  阻止备库在崩溃后自动启动复制

- read_only

  备库的只读选项

- sync_master_info = 1 、 sync_relay_log = 1 、 sync_relay_log_info = 1

  使master.info和中继日志文件在崩溃时安全。但是额外的fsync()将会增加性能开销。

### 复制文件

- mysql-bin.index

  当在服务器上开启二进制日志时，同时会生成一个和二进制日志同名的但以.index作为后缀的文件，该文件用于记录磁盘上的二进制日志文件，这个文件的每一行包含了二进制文件的文件名。

- mysql-relay-bin-index

  这个文件是中继文件的索引文件，和mysql-bin.index的作用类似

- master.info

  这个文件用于保存备库连接到主库所需要的信息，格式为纯文本。

- relay-log.info

  这个文件包含了当前备库复制的二进制日志和中继日志坐标

### 发送复制文件到其它备库

- log-slave-updates: 

  这个选项可以让备库成为其它服务器的主库，mysql会将执行过的事件记录到它自己的二进制日志中，这样它的备库就可以从其日志中检索并执行事件。

### 复制过滤器

- binlog_do_db、binlog_ignore_db: 

  在主库上控制某些事件是否记录到二进制文件中，可以用于控制复制过滤，但不建议开启，当需要二进制日志恢复时将会缺少数据。

- replicate_do_db、replicate_do_table、replicate_ignore_db、replicate_ignore_table、replicate_rewrite_db、replicate_wild_do_table、replicate_wild_ignore_table：

  过滤重继日志的重放，在从中继日志中读取事件时进行过滤。可以控制或忽略一个或多个数据库，把一个数据库重写到另外一个数据库，或使用类似like的模式复制或者忽略数据库表。

不到万不得已，不要使用复制过滤！

### 复制拓扑

- 一个mysql备库实例只能有一个主库
- 每个备库必须有一个唯一的服务器id
- 一个主库可以有多个备库
- 如果打开了log_slave_updates选项，一个备库可以把其主库上的数据传播到其它备库。

#### 一主库多备库

适合少量写大量读，把读分摊到多个备库上，直到备库给主库造成了太大的负担，或者主备之间的带宽成为瓶颈为止。

- 为不同的角色使用不同的备库（例如添加不同的索引或者使用不同的存储引擎）
- 把一台备库当作待用的主库，除了复制没有其它数据传递
- 把一台备库放到远程数据中心，用作灾难恢复
- 延迟一个或多个备库，以备灾难恢复
- 使用其中一个备库，作为备份、培训、开发或者测试使用服务器

#### 主动-主动模式下的主-主复制

两个主机相互复制且均可写，一般用于两个地理位置的办公室都需要一份可写的数据拷贝。

这种配置最大的问题是如何解决冲突

#### 主动-被动模式下的主-主复制

两个主机互相复制，但是只有一台主机可写。

1.确保两台服务器上有相同的数据。

2.启用二进制日志，选择唯一的服务器id，并创建复制账号

3.启用备库更新的日志记录，这是故障转移和故障恢复的关键

4.把被动服务器配置成只读，防止可能与主动服务器上的高兴产生冲突

5.启动每个服务器上的mysql实例

6.将每个主库设置为对方的备库，使用新创建的二进制日志开始工作

类似于创建一个热备份，但是同时可以用这个"备份"提高性能，例如，用它来执行读操作、备份、"离线"维护以及升级等。

可以为主-主复制的每个主库添加备库，用于一主库多备库的工作

#### 分发主库

将分发备库的表修改为blackhole存储引擎，这种引擎不会做实际的查询，分发备库的唯一目的就是提取和提供主库的二进制日志，以减少主库的负载。

备库数量较多时，可以使用树或金字塔型，以保证每一个库的备库至多不超过十个。

#### 定制的复制方案

如果每个备库只拥有主库的一部分数据，并且将读分配给备库，就可以很好的利用备库的内存。

每个备库通过选项replicate_wile_do_table选项来限制给定数据库的数据

如：replicate_wile_do_talbe = sales.%， 表示只重放来自sales数据库的数据

分离不同的查询到不同的备库上，对不同的查询设置不同的硬件、配置、索引和引擎。

### 复制的管理和维护

#### 监控复制

- show master logs：

  在主库上运行，可以查看当前主库的二进制日志位置和配置。

- show binlog event：

  在主库上运行，可以查看复制事件。

- show slave status：

  在备库上使用，可以查看备库中复制的情况。

推荐监控工具：Percona Toolkit、Percona XtraBackup

#### 测量复制延迟

- pt-heartbeat：

  脚本，复制心跳的一种实现。使用复制心跳可以准确的确定出备库的复制延迟。

#### 确定主库备库数据是否一致

- pt-table-checksum：

  能够确认主库和备库的数据是否一致

- pt-table-sync：

  可以解决主库和备库表上的不同。

#### 改变主库

在备库上使用change master to命令，指定适合的值。

将备库提升为主库的操作：

计划内

1.停止当前主库上所有写操作，可以断开所有的客户端连接以关闭所有打开的事务。

2.通过flush table with read lock在主库上停止所有活跃的写入，这一步是可选的，也可以在主库上设置read_only选项。为了更好的保证阻止已存在的事务继续提交，kill所有打开的线程。

3.选择一个备库作为新的主库，确保它以及完全跟上主库（如，让它执行完所有从主库获得的中继日志）

4.确保新主库和旧主库的数据是一致的

5.在新主库上执行stop slave

6.在新主库上执行change master to master_host = ‘’, 然后执行reset slave，使其断开与老主库的连接，并丢弃master.info里记录的信息。

7.执行show master status 记录新主库的二进制日志坐标

8.确保其它备库已经追赶上。

9.关闭旧主库。

10.激活新主库上事件。

11.将客户端连接到新主库。

12.在每台备库上执行change master to语句，使用之前通过show master status获得二进制日志坐标，来指向新的主库。

13.如果新主库与旧主库的配置不同，则需要更改一些选项，如innodb_flush_log_at_trx_commit选项

计划外

1.确定哪台备库的数据最新。检查每台备库上show slave status命令的输出，选择其中master_log_file/read_master_log_pos的值最新的那个。

2.让所有备库执行完所有其从崩溃前的旧主库那获得的中继日志。

3.在新主库上执行stop slave

4.在新主库上执行change master to master_host = ‘’, 然后执行reset slave，使其断开与老主库的连接，并丢弃master.info里记录的信息。

5.执行show master status 记录新主库的二进制日志坐标

6.比较每台备库和新主库的master_log_file/read_master_log_pos的值

7.激活新主库上事件。

8.将客户端连接到新主库。

9.在每台备库上执行change master to语句，使用之前通过show master status获得二进制日志坐标，来指向新的主库。

## 可扩展性

向上扩展（垂直扩展）：购买更多性能强悍的硬件

向内扩展：归档和清理不需要的数据，可以使用Percona Toolkit的pt-archiver在后台运行，移除不需要的数据

向外扩展（横向扩展、水平扩展）：复制、拆分、数据分片

节点：一个主主复制结构/一个主库和多个备库/一个主动服务器并使用分布式复制块设备作为备用服务器/一个基于存储区域网络的集群

- 按功能拆分：按照不同的功能分区将不同种类的数据放在不同的节点上
- 数据分片：按照数据的标识（如用户id）将同种数据分布在不同的节点上

在节点上部署分片的方法：

- 每个分片使用单一数据库，并且数据库名要相同
- 将多个分片放入一个数据库中，每个表名上包含分片号
- 为每个分片使用一个数据库，并在数据库中包含所有应用需要的表。
- 每个分片使用一个数据库，并在数据库名和表名中包含分片号
- 每个节点运行多个mysql实例，每个实例上有一个或多个分片

固定分配：使用某种特定的规则分配分片数据，不需要目录表

动态分配：使用某种规则分配分片数据，同时需要生成目录表用于查询

负载均衡：在服务器前端设置一个负载均衡器（一般是专门的硬件设备）。负载均衡器将请求的连接路由到最空闲的可用服务器。可以在应用服务器到数据库服务器之间引入中间件。

## 高可用性

增加可用时间占总时间的比率，即减少宕机时间

常见问题：

- 磁盘空间耗尽
- 糟糕的sql
- 糟糕的schema和索引设计
- 主备数据不一致
- drop table的误操作

建议：

- 测试恢复工具和流程，包括从备份中恢复数据
- 遵从最小权限原则
- 保持系统干净、整洁
- 使用好的命名和组织约定来避免产生混乱，例如服务器适用于开发还适用于生产环境
- 谨慎安排升级数据库服务器
- 在升级前，使用诸如percona toolkit中的pt-upgrade之类的工具仔细检查系统。
- 使用innodb并进行适当的配置，确保innodb使默认存储引擎。
- 确认基本的服务器配置是正确的
- 通过skip_name_resolve禁止DNS
- 除非证明有效，否则禁用查询缓存
- 避免使用复杂的特性，例如复制过滤和触发器，除非确实需要
- 监控重要的组件和功能，特别是像磁盘空间和raid卷状态这样的关键项目，但他要避免误报，只有当确实发生问题时才报警
- 尽量记录服务器的状态和性能指数，如果可能尽量永久地保存
- 定期检查复制完整性
- 将备库设置为只读，不要让复制自启动
- 定期进行查询语句审查
- 归档并清理不需要的数据
- 为文件系统保留一些空间，在linux中用-m选项为文件系统本身保留空间
- 评估和管理系统的改变、状态以及性能信息。

## 备份与恢复

建议：

- 在生产实践中，对于大数据库来说，物理备份是必须的，逻辑备份太慢并受到资源限制，从逻辑备份中恢复需要很长时间。基于快照的备份，例如Percona XtraBackup和MySQL interprise Backup是最好的选择。对于小的数据库，逻辑备份可以很好的胜任。
- 保留多个数据集
- 定期从逻辑备份（或者物理备份）中抽取数据进行恢复测试
- 保留二进制日志以用于基于故障时间点的恢复。exprie_logs_days参数应该设置的足够长，至少可以从最近两次物理备份中做基于时间点的恢复，这样可以在保持主库运行且不应用任何二进制日志的情况下创建一个备库，备份二进制日志与过期设置无关，二进制日志备份需要保存足够长的时间，以便能从最近的逻辑备份进行恢复。
- 完全不借助备份工具本身来监控备份和备份的过程，需要另外验证备份是否正常

离线备份：关闭MySQL进行备份

在线备份：常常使用flush table with read lock操作，如果只使用innodb表，可以避免使用该操作。

逻辑备份：

- 优点
  - 逻辑备份是可以用编辑器或者像grep和sed之类的指令查看和操作的普通文件。当需要恢复数据或指向查看查看数据但不回复时，这都非常有帮助
  - 恢复非常简单，可以通过管道把它们输入到mysql，或者使用mysqlimport
  - 可以通过网络来备份和恢复——就是说，可以在与mysql主机不同的另外一台主机上操作
  - 可以在不能访问底层文件系统的系统中使用
  - 非常灵活，因为mysqldump等工具可以接受许多选项
  - 与存储引擎无关，因为是从mysql服务器中提取数据而生成，所以消除了底层数据存储和不同。
  - 有助于避免数据损坏。如果磁盘驱动器有故障而要复制原始文件时，将会得到一个错误并且部分损坏的备份。如果mysql在内存中的数据没有损坏，有时可以得到一个可以信赖的逻辑备份。
- 缺点
  - 必须由数据库服务器完成逻辑备份的工作，因此要使用更多的CPU周期
  - 逻辑备份在某些场景下比数据库文件本身更大。ASCⅡ形式的数据不总是和存储引擎数据一样高效。
  - 无法保证导出后再还原出来的一定是同样的数据，尽管非常少见。
  - 从逻辑备份中还原需要mysql加载和解释语句，转化为存储格式，并重建索引。所有这一切会很慢。

逻辑备份分为两种类型SQL导出和符号分隔文件。

SQL导出：mysqldump的默认方式，导出文件包含表结构和数据，均以有效的sql命令形式给出。导出的输出对于还原操作来说是可行的。

符号分隔文件备份：可以使用sql命令select into outfile以符号分隔文件格式创建数据的逻辑备份（可以用mysqldump的--tab选项导出到符号分隔文件中）。符号分隔文件要更紧凑且更易于用命令行工具操作，这种方法最大的优点是备份和还原速度更快。

物理备份：

- 优点
  - 基于文件的物理备份，只需要将需要的文件复制到其他地方即可完成备份，不需要额外的工作来生成原始文件。
  - 物理备份的恢复可能就更简单了，这取决于存储引擎。对于myIsam，只需要简单地复制文件到目的地即可。对于innodb则需要停止数据库服务，还可能需要采取一些其他步骤。
  - innodb和myisam的物理备份非常容易跨平台、操作系统和MySQL版本（逻辑导出亦是如此）
  - 从物理备份中恢复会更快。
- 缺点
  - innodb的原始文件通常比相应的逻辑备份要大得多。innodb的表空间往往包含很多未使用的空间。还有很多空间被用来做存储数据以外的用途（插入缓冲，回滚段等）。
  - 物理备份不总是可以跨平台、操作系统和mysql版本。文件名大小写敏感和浮点格式时可能会遇到的麻烦。

物理备份常用的为LVM文件系统快照。注意，快照是写时复制，只包含实际数据和快照发生的时间点的数据之间的差异。这代表快照并不等同于实际的备份。

建议：先使用物理备份，以此数据启动mysql服务器并运行mysqlcheck。然后周期性地使用mysqldump执行逻辑备份。

备份内容：

- 数据库内数据

- 非显著数据：例如二进制日志和innodb事务日志

- 代码：例如触发器和存储过程

- 复制配置：所有与复制相关的文件

- 服务器配置

- 选定的操作文件：可能包括cron任务、用户和组的配置、管理脚本、sudo规则等

增量备份：自从任意类型的上次备份后所有修改做的备份

差异备份：自上次全备份所有改变的部分而做的备份

建议：

- 使用Percona XtraBackup和Mysql Enterprise Backup中的增量备份特性
- 备份二进制日志，可以在每次备份后使用flush logs来开是一个新的二进制日志，这样就只需要备份新的二进制日志
- 不要备份没有改变的表，不要备份没有改变的行
- 某些数据根本不需要备份
- 备份所有的数据，建议至少一周做一次全备

可以使用pt-slave-delay让一个复制故意延迟一段时间，可以用于容灾。

恢复备份：

- 停止mysql服务器
- 记录服务器的配置和文件权限
- 将数据从备份中移到mysql数据目录
- 改变配置
- 改变文件权限
- 以限制访问模式重启服务器，等待完成启动
- 载入备份文件
- 检查和重放二进制日志
- 检测已经还原的数据
- 以完全权限重启服务器

